{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BPDhz3Rq8T13",
        "WzD0KWhOBQJm",
        "lrs9lCkA_-uh",
        "wo4oUCFz8OTj",
        "79duTacmnIIW",
        "HISCFH_xng9p",
        "1b9fepeGnoci",
        "FimmkYWvoGYu",
        "CfKMlwpY_x6w",
        "q5qO65Wcmz7-",
        "oNZV2WC-qBzz",
        "NAz_NE_2rcPG",
        "zc57lqEm2RhB",
        "DzXD9OMo7iCD",
        "foCxu7cg2WUb",
        "1jL2Hb8Lyple",
        "G2dEQ9d4yl2s",
        "17uQ12P-zGeG",
        "pLSyq_9FzT5t",
        "Q7Q-rJjO_N_g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Explorando Datos del Mundo Real con Python***\n",
        "\n",
        "\n",
        "```\n",
        "Bahurlet, Micaela\n",
        "Domé Florencia\n",
        "Spinetta Carlos\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xDiSHzZFBoYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Respuestas"
      ],
      "metadata": {
        "id": "BPDhz3Rq8T13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1**"
      ],
      "metadata": {
        "id": "WzD0KWhOBQJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Link al DataSet\n",
        "\n",
        "https://www.kaggle.com/datasets/mjshubham21/movie-dataset-for-analytics-and-visualization?resource=download\n"
      ],
      "metadata": {
        "id": "fFPMXiuxBUqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2**"
      ],
      "metadata": {
        "id": "lrs9lCkA_-uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1 Importamos Librerias y DataSet"
      ],
      "metadata": {
        "id": "wo4oUCFz8OTj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z_UR9Ug98QPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "7241a3e3-359a-4817-c38d-3296677b619d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mjshubham21/movie-dataset-for-analytics-and-visualization?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 62.1M/62.1M [00:02<00:00, 23.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mjshubham21/movie-dataset-for-analytics-and-visualization/versions/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/movie-dataset-for-analytics-and-visualization/movies_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-174537789.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to dataset files:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/movie-dataset-for-analytics-and-visualization/movies_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/movie-dataset-for-analytics-and-visualization/movies_dataset.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#df= pd.read_csv(\"movies_dataset.csv\")\n",
        "#df\n",
        "#Kaggle tiene una opcion para importar directamente el dataset\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"mjshubham21/movie-dataset-for-analytics-and-visualization\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "df= pd.read_csv(\"/kaggle/input/movie-dataset-for-analytics-and-visualization/movies_dataset.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.1Dimensiones\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "79duTacmnIIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Dimensiones\n",
        "print(\"dimensiones\", df.shape)"
      ],
      "metadata": {
        "id": "YST0CWnA-n8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.2 Tipos de datos"
      ],
      "metadata": {
        "id": "HISCFH_xng9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Tipos de datos de cada columna\n",
        "print(\"\\nTipos de datos:\",df.dtypes)"
      ],
      "metadata": {
        "id": "T4xBBTrF-3T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.3 Valores nulos"
      ],
      "metadata": {
        "id": "1b9fepeGnoci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Cantidad de valores nulos por columna\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "O5frcdtj_BUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3"
      ],
      "metadata": {
        "id": "FimmkYWvoGYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categoricas = ['Title', 'Genre', 'Director']\n",
        "numericas   = ['ReleaseYear', 'BudgetUSD', 'One_Week_SalesUSD']\n",
        "\n",
        "print(\"\\nVariables categóricas seleccionadas:\", categoricas)\n",
        "print(\"Variables numéricas seleccionadas:\", numericas)"
      ],
      "metadata": {
        "id": "MzDTDM4qAB6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3**"
      ],
      "metadata": {
        "id": "CfKMlwpY_x6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.A"
      ],
      "metadata": {
        "id": "q5qO65Wcmz7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "budget_array = df['BudgetUSD'].dropna().to_numpy()\n",
        "sales_array  = df['One_Week_SalesUSD'].dropna().to_numpy()"
      ],
      "metadata": {
        "id": "M9FOpKVXqA-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.B"
      ],
      "metadata": {
        "id": "oNZV2WC-qBzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Arrays creados correctamente de Presupuesto(BudgetUSD).\")\n",
        "print(\"\\nPresupuesto(BudgetUSD) Media:\", np.mean(budget_array))\n",
        "print(\"Presupuesto(BudgetUSD)  Mediana:\", np.median(budget_array))\n",
        "print(\"Presupuesto(BudgetUSD) Desviación estándar:\", np.std(budget_array))\n",
        "print(\"Presupuesto(BudgetUSD) Percentiles (25, 50, 75):\", np.percentile(budget_array, [25, 50, 75]))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Arrays creados correctamente de las ventas una semana despues(One_Week_SalesUSD).\")\n",
        "print(\"\\nVentas una semana despues Media:\", np.mean(sales_array))\n",
        "print(\"Ventas una semana despues  Mediana:\", np.median(sales_array))\n",
        "print(\"Ventas una semana despues Desviación estándar:\", np.std(sales_array))\n",
        "print(\"Ventas una semana despues Percentiles (25, 50, 75):\", np.percentile(sales_array, [25, 50, 75]))"
      ],
      "metadata": {
        "id": "krvl1WRXI-RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.C"
      ],
      "metadata": {
        "id": "NAz_NE_2rcPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ordenamos los valores en base a el Rating en IMDb\n",
        "orden = df.sort_values(by=\"IMDbRating\", ascending=False)\n",
        "#Asignamos a una variable los 10 primeros en base las ventas en el día de estreno\n",
        "valores_dia_estreno = orden.head(10)['Opening_Day_SalesUSD'].dropna().to_numpy()\n",
        "#Los visualizamos\n",
        "print(valores_dia_estreno)\n"
      ],
      "metadata": {
        "id": "ojHZHtATsuju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Acá usamos valores_dia_estreno para visualizar el escalado\n",
        "# Min-Max\n",
        "val_min = np.min(valores_dia_estreno)\n",
        "val_max = np.max(valores_dia_estreno)\n",
        "info_escalada = (valores_dia_estreno - val_min) / (val_max - val_min)\n",
        "\n",
        "print(\"Datos originales: \\n\", valores_dia_estreno,\"\\n\")\n",
        "print(\"Min-Max de la info escalada: \\n\", info_escalada, \"\\n\")\n"
      ],
      "metadata": {
        "id": "go8NVH0urfte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4**"
      ],
      "metadata": {
        "id": "zc57lqEm2RhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.1\n",
        "\n",
        "No teniamos valores núlos o faltantes."
      ],
      "metadata": {
        "id": "dIomVOih-9gK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.2"
      ],
      "metadata": {
        "id": "DzXD9OMo7iCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#seleccionamos los dramas únicamente y lo agrupamos\n",
        "dramax = df.loc[df[\"Genre\"] == \"Drama\"]\n",
        "\n",
        "primeros_quince_dramas = dramax.head(15)\n",
        "\n",
        "print(\"Resumen variables Categóricas:\\n\")\n",
        "print(primeros_quince_dramas[['Genre', 'BudgetUSD', 'One_Week_SalesUSD']].describe())"
      ],
      "metadata": {
        "id": "vjnzytU07z0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.3"
      ],
      "metadata": {
        "id": "foCxu7cg2WUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#queriamos usar df['mes'] = df['ReleaseDate'].dt.month\n",
        "#Pero habia que convertirlo a datatime\n",
        "df['ReleaseDate'] = pd.to_datetime(df['ReleaseDate'])\n",
        "#Creamos la Columna Mes_Estreno\n",
        "df['mes_estreno'] = df['ReleaseDate'].dt.month\n"
      ],
      "metadata": {
        "id": "msdxMSVA2Ur5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Acá creamos la Columna Ganacicas_diarias\n",
        "df['Ganancias_Diarias_Cientifica'] = (df['One_Week_SalesUSD'] - df['Opening_Day_SalesUSD']) / 6\n",
        "df['Ganancias_Diarias_Decimal'] = ((df['One_Week_SalesUSD'] - df['Opening_Day_SalesUSD']) / 6)/1_000\n",
        "#df.describe"
      ],
      "metadata": {
        "id": "6TDA9HF_4We7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Otra columna que sea el ROI - retorno de la inversión en porcentajes\n",
        "\n",
        "df['ROI'] = ((df['Global_BoxOfficeUSD'] / df['BudgetUSD']) * 100)\n",
        "df"
      ],
      "metadata": {
        "id": "_UsnVbYyAu-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"peliculas_modificado.csv\", index=False)   # Exportar el DataFrame modificado a CSV"
      ],
      "metadata": {
        "id": "3TltZ2HX6lgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5**"
      ],
      "metadata": {
        "id": "1jL2Hb8Lyple"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.1"
      ],
      "metadata": {
        "id": "G2dEQ9d4yl2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================Distribución========================================================\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df['ReleaseYear'], bins=20, kde=True, color=\"skyblue\")\n",
        "plt.title(\"Distribución de Años de Estreno\", fontsize=14)\n",
        "plt.xlabel(\"Año\")\n",
        "plt.ylabel(\"Cantidad de Películas\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MFVZGTUbyjim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2"
      ],
      "metadata": {
        "id": "17uQ12P-zGeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================Comparativo======================================================\n",
        "#Opening_Day_SalesUSD\n",
        "#Vamos a tratar de agarrar los 15 mejores de ahí ylos 15 peores\n",
        "#ordenamos por recaudación de estreno con el método sortvalues para ordenar un df en base a sus columnas, en este caso de mayor a menor\n",
        "orden_arriba = df.sort_values(by=\"Opening_Day_SalesUSD\", ascending=False)\n",
        "#orden_abajo = df.sort_values(by=\"Opening_Day_SalesUSD\", ascending=True)\n",
        "\n",
        "quincemejores = orden_arriba.head(15)\n",
        "quincepeores = orden_arriba.tail(15)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=quincemejores, x=\"Title\", y=\"Global_BoxOfficeUSD\", hue=\"Country\",alpha=0.6)\n",
        "plt.legend(title=\"Región\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.title(\"Relación entre Pais y Ventas Globales\", fontsize=14)\n",
        "plt.xlabel(\"Presupuesto (millones USD)\")\n",
        "plt.ylabel(\"Ventas Globales (millones USD)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "#gráfico de barra barplot con Seaborn."
      ],
      "metadata": {
        "id": "77BFrvOezBOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.3"
      ],
      "metadata": {
        "id": "pLSyq_9FzT5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=================================Serie temporal===============================================================\n",
        "\n",
        "#a través de matplot, definimos como argumento un 18, 6\n",
        "plt.figure(figsize=(18,6))\n",
        "#a través de seaborn usamos lineplot, pasamos como parámetro el año de estreno y las ventas globales\n",
        "sns.lineplot(data=df, x=\"ReleaseYear\", y=\"Global_BoxOfficeUSD\", marker=\"o\")\n",
        "\n",
        "plt.title(\"Evolución de Ventas Globales por Año de Estreno\", fontsize=14)\n",
        "plt.xlabel(\"Año de Estreno\")\n",
        "plt.ylabel(\"Ventas Globales (millones USD)\")\n",
        "plt.show()\n",
        "\n",
        "#gráfico lineplot, permite evidenciar la evolución de las ventas gloales en el tiempo."
      ],
      "metadata": {
        "id": "VWa0WOSKzLy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.4"
      ],
      "metadata": {
        "id": "Q7Q-rJjO_N_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=================================================================================================================\n",
        "#con sortvalues, nuevamente ordenamos la columna re rainting de mayor a mejor, queriamos las más valoradas\n",
        "para_heat = df.sort_values(by=\"IMDbRating\", ascending=False)\n",
        "#Asignamos a una variable los 10 primeros en base las ventas en el día de estreno\n",
        "heat_map = para_heat.head(10)\n",
        "# Seleccionamos columnas de interés y ponemos películas como índice\n",
        "df_heatmap = heat_map.set_index(\"Title\")[[\"Opening_Day_SalesUSD\", \"One_Week_SalesUSD\", \"Global_BoxOfficeUSD\"]]\n",
        "\n",
        "# Heatmap, mapa de calor\n",
        "plt.figure(figsize=(8,5))\n",
        "#valores dentro de cada celda, decimales y paleta de coores yellow, green y blue\n",
        "sns.heatmap(df_heatmap, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
        "\n",
        "#mpás oscuro, mas ventas, más claro menos ventas.\n",
        "plt.title(\"Heatmap: Ventas por Periodo\", fontsize=14)\n",
        "plt.ylabel(\"Película\")\n",
        "plt.xlabel(\"Periodo\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cdhpslBlJ03y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6**"
      ],
      "metadata": {
        "id": "_J466fi_C90N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Responder 3 preguntas de investigación que se plantearon sobre los datos"
      ],
      "metadata": {
        "id": "pzdVDGTRDA2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- ¿Hubo periodos de mayor o menor producción cinemátográfica?\n",
        "\n",
        "Con el gráfico de distribución de la consigna 5.1 pudimos identificar los periodos de crecimiento o decrecimiento en cuanto a la producción cinematográfica. Evidenciando así el aumento o la depresión en ciertas décadas.\n",
        "\n",
        "Identificamos que: en 1950 el porcentaje de producción de películas fue el menor y en el año 2020 la producción aumentó considerablemente, alcanzando más de 80.000 películas."
      ],
      "metadata": {
        "id": "GYjFzgFIDHxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- ¿Cómo ha evolucionado la recaudación global de las películas según su año de estreno?\n",
        "\n",
        "A partir del gráfico 5.3 pudimos dar respuesta a la incógnita de cómo ha evolucionado la recaudación global de películas, permitiendo identificar años record en recaudación, estancamientos o caídas significativas.\n",
        "\n",
        "Identificamos que: el pico de ventas globales se dió en la década de 1950-1960. y la mayor depresión se dió a mediados de la década de 1900-2000."
      ],
      "metadata": {
        "id": "mdz1ALN0DU7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- ¿Cuáles son las películas con mayores ventas globales y de qué país son?\n",
        "\n",
        "A través del gráfico 5.2 pudimos reconocer cuales películas fueron más exitosas en su estreno y a qué país pertenecen.\n",
        "\n",
        "Identificamos que:\n",
        "- USA es un país que ha generado muchos picos de ventas globales a través de sus películas.\n",
        "- Canadá, con \"single idea\" alcanzó record en ventas globales\n",
        "- Japón, con \"Enjoy assume\" también alcanzó un buen porcentaje de ventas globales, seguido por UK y Australia."
      ],
      "metadata": {
        "id": "plEH3zdjGthj"
      }
    }
  ]
}